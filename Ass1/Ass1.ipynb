{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_inputs = [4.0, -1.0]\n",
    "k_pre = [1.0, 1.0, 1.0]\n",
    "h_hidden = [1.0, 1.0, 1.0]\n",
    "w_weights = [[1.0, 1.0, 1.0], [1.0, 1.0, 1.0]] # input : x_input x k_hidden : 2 x 3\n",
    "v_weights = [1.0, 1.0, 1.0]\n",
    "b_bias = 1\n",
    "c_bias = 1\n",
    "t_target = 1.2\n",
    "y = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + (math.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(i, outputs):\n",
    "    # print(i, outputs)\n",
    "    den = 0\n",
    "    for j in range(len(outputs)):\n",
    "        den += math.e ** outputs[j]\n",
    "        \n",
    "    if den == 0:\n",
    "        return 0\n",
    "    \n",
    "    return (math.e ** outputs[i]) / den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def forward(y):\n",
    "#     for j in range(3): # num first layer nodes\n",
    "#         for i in range(2): # num inputs\n",
    "#             k_pre[j] += w_weights[i][j] * x_inputs[i]\n",
    "#         k_pre[j] += b_bias\n",
    "#     print(f'k_pre: {k_pre}')\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         h_hidden[i] = sigmoid(k_pre[i])\n",
    "#     print(f'h_hidden: {h_hidden}') \n",
    "    \n",
    "#     for i in range(3):\n",
    "#         y += h_hidden[i] * v_weights[i]\n",
    "     \n",
    "#     y += c_bias\n",
    "#     print(f'y: {y}')\n",
    "    \n",
    "#     loss = (y - t_target) ** 2\n",
    "#     print(f'loss: {loss}')  \n",
    "    \n",
    "#     return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dldv = [0.0, 0.0, 0.0]\n",
    "dldh = [0.0, 0.0, 0.0]\n",
    "dldc = 0.0\n",
    "dldk = [0.0, 0.0, 0.0]\n",
    "dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "dldb = [0.0, 0.0, 0.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def backward():\n",
    "#     dldy = 2 * (y - t)\n",
    "#     print(f'dldy: {dldy}')\n",
    "#     for i in range(3):\n",
    "#         # these two are the deriv from y=v1h1 + v2h2 +..\n",
    "#         dldv[i] = dldy * h_hidden[i] # dldv = dldy * dydv\n",
    "#         dldh[i] = dldy * v_weights[i] # dldh = dldy * dydh\n",
    "        \n",
    "#     print(f'dldv: {dldv}')\n",
    "#     print(f'dldh: {dldh}')\n",
    "    \n",
    "#     dldc = dldy\n",
    "#     print(f'dldc: {dldc}')\n",
    "    \n",
    "#     for i in range(3):\n",
    "#         dldk[i] = dldh[i] * h_hidden[i] * (1 - h_hidden[i]) # dldk = dldh * dhdk\n",
    "#         # dhdk is the deriv of sigmoid func\n",
    "    \n",
    "#     print(f'dldk: {dldk}')\n",
    "        \n",
    "#     for j in range(3):\n",
    "#         for i in range(2):\n",
    "#             dldw[i][j] = dldk[j] * x_inputs[i] # dldw = dldk * dkdw\n",
    "#             # dkdw is deriv of k1 = w1x1 + w2x2 + ..\n",
    "#         dldb[j] = dldk[j]\n",
    "\n",
    "#     print(f'dldw: {dldw}')\n",
    "#     print(f'dldb: {dldb}')\n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above is the network from the slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y, t):\n",
    "    # if abs(t - y) < 1.0e-15 or y == 0:\n",
    "    #     return 1.0e-15\n",
    "    # print(y,t)\n",
    "    ce = -1 * t * math.log(y)\n",
    "    # print(y,t,ce)\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[6.257306904087134, 6.308485959384342],\n",
       " [6.338035923436525, 2.675551066603548],\n",
       " [-3.895993194508998, 4.900830834063052]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rand_weights(r, c):\n",
    "    arr_r = []\n",
    "    for j in range(r):\n",
    "        arr_c = []\n",
    "        for i in range(c):\n",
    "            arr_c.append(random.uniform(-10, 10))\n",
    "        arr_r.append(arr_c)\n",
    "    return arr_r\n",
    "            \n",
    "    \n",
    "rand_weights(3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP:\n",
    "    def __init__(self):\n",
    "        # self.k_pre = [0.0, 0.0, 0.0]\n",
    "        # self.h_hidden = [0.0, 0.0, 0.0]\n",
    "        # self.w_weights =  [[1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]] # rand_weights(2, 3)  # input : x_input x k_hidden : 2 x 3\n",
    "        # self.v_weights = [[1.0, 1.0], [-1.0, -1.0], [-1.0, -1.0]]  # rand_weights(3, 2) # # \n",
    "        # self.b_weights = [0.0, 0.0, 0.0]\n",
    "        # self.c_weights = [0.0, 0.0]\n",
    "        # self.y_outputs = [0.0, 0.0]\n",
    "        # self.o_raw = [0.0, 0.0]\n",
    "        # self.loss = [0.0, 0.0]\n",
    "        \n",
    "        # self.dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "        # self.dldh = [0.0, 0.0, 0.0]\n",
    "        # self.dldc = [0.0, 0.0]\n",
    "        # self.dldk = [0.0, 0.0, 0.0]\n",
    "        # self.dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "        # self.dldb = [0.0, 0.0, 0.0]\n",
    "        # self.dldo = [0.0, 0.0]\n",
    "        # self.dldy = [0.0, 0.0]\n",
    "        self.logs = True\n",
    "    \n",
    "    def forward(self, x_inputs, w_weights, b_weights, v_weights, c_weights):\n",
    "        k_pre = [0.0, 0.0, 0.0]\n",
    "        h_hidden = [0.0, 0.0, 0.0]\n",
    "        o_raw = [0.0, 0.0]\n",
    "        y_outputs = [0.0, 0.0]\n",
    "        \n",
    "        if self.logs: print(f'x_inputs: {x_inputs}')\n",
    "        \n",
    "        for j in range(3): \n",
    "            for i in range(2):\n",
    "                k_pre[j] += w_weights[i][j] * x_inputs[i]\n",
    "            k_pre[j] += b_weights[j]\n",
    "        if self.logs: print(f'k_pre: {k_pre}') \n",
    "        \n",
    "        for i in range(3):\n",
    "            h_hidden[i] = sigmoid(k_pre[i])\n",
    "        if self.logs: print(f'h_hidden: {h_hidden}') \n",
    "        \n",
    "        for j in range(2): \n",
    "            for i in range(3): \n",
    "                o_raw[j] += v_weights[i][j] * h_hidden[i] \n",
    "            o_raw[j] += c_weights[j]\n",
    "        if self.logs: print(f'o_raw: {o_raw}') \n",
    "        \n",
    "        \n",
    "        for i in range(2):\n",
    "            y_outputs[i] = softmax(i, o_raw)\n",
    "        if self.logs: print(f'y_outputs: {y_outputs}') \n",
    "        \n",
    "        return y_outputs, h_hidden\n",
    "            \n",
    "        \n",
    "    def loss(self, y_outputs, t_targets):\n",
    "        print(y_outputs, t_targets)\n",
    "        loss = 0\n",
    "        for i in range(2):\n",
    "            ce = cross_entropy(y_outputs[i], t_targets[i])\n",
    "            print(ce)\n",
    "            loss += ce\n",
    "        if self.logs: print(f'loss: {loss}')  \n",
    "        \n",
    "        return loss\n",
    "        \n",
    "    def backward(self, y_outputs, t_targets, h_hidden, v_weights, x_inputs, dldw, dldb, dldv, dldc):\n",
    "        dldh = [0.0, 0.0, 0.0]\n",
    "        dldk = [0.0, 0.0, 0.0]\n",
    "        dldo = [0.0, 0.0]\n",
    "        # dldy = [0.0, 0.0]\n",
    "        \n",
    "        for i in range(2):\n",
    "            dldo[i] += y_outputs[i] - t_targets[i]\n",
    "        if self.logs: print(f'dldo: {dldo}')\n",
    "        \n",
    "        for j in range(3):\n",
    "            for i in range(2):\n",
    "                dldv[j][i] += dldo[i] * h_hidden[j]\n",
    "                dldh[j] += dldo[i] * v_weights[j][i]      \n",
    "        if self.logs: print(f'dldv: {dldv}')\n",
    "        if self.logs: print(f'dldh: {dldh}')\n",
    "        \n",
    "        dldc = dldo\n",
    "        if self.logs: print(f'dldc: {dldc}')\n",
    "        \n",
    "        for i in range(3):\n",
    "            dldk[i] += dldh[i] * h_hidden[i] * (1 - h_hidden[i]) \n",
    "\n",
    "        if self.logs: print(f'dldk: {dldk}')\n",
    "            \n",
    "        # print('stuff: ', dldk, x_inputs)\n",
    "        for j in range(3):\n",
    "            for i in range(2):\n",
    "                dldw[i][j] += dldk[j] * x_inputs[i] \n",
    "            \n",
    "        dldb = dldk\n",
    "\n",
    "        if self.logs: print(f'dldw: {dldw}')\n",
    "        if self.logs: print(f'dldb: {dldb}')\n",
    "        \n",
    "        return dldw, dldb, dldv, dldc\n",
    "        \n",
    "    def set_inputs(self, x_inputs):\n",
    "        self.x_inputs = x_inputs\n",
    "        \n",
    "    def set_targets(self, t_targets):\n",
    "        self.t_targets = t_targets\n",
    "        \n",
    "    def set_learning_rate(self, lr):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def sgd(self, lr, w_weights, b_weights, v_weights, c_weights, dldw, dldb, dldv, dldc):\n",
    "        for j in range(3):\n",
    "            for i in range(2):\n",
    "                diff = -lr * dldv[j][i]\n",
    "                # if logs: print(f'diff v: {diff}')\n",
    "                v_weights[j][i] += diff\n",
    "                \n",
    "        for j in range(2):\n",
    "            for i in range(3):\n",
    "                diff = -lr * dldw[j][i]\n",
    "                # if logs: print(f'diff w: {diff}')\n",
    "                w_weights[j][i] += diff\n",
    "                \n",
    "        for j in range(2):\n",
    "            diff = -lr * dldc[j]\n",
    "            # if logs: print(f'diff w: {diff}')\n",
    "            c_weights[j] += diff\n",
    "        \n",
    "        for j in range(3):\n",
    "            diff = -lr * dldb[j]\n",
    "            # if logs: print(f'diff w: {diff}')\n",
    "            b_weights[j] += diff\n",
    "            \n",
    "        return v_weights, w_weights, c_weights, b_weights\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_inputs: [1, -1]\n",
      "k_pre: [2.0, 2.0, 2.0]\n",
      "h_hidden: [0.8807970779778823, 0.8807970779778823, 0.8807970779778823]\n",
      "o_raw: [-0.8807970779778823, -0.8807970779778823]\n",
      "y_outputs: [0.5, 0.5]\n",
      "yes [0.5, 0.5] [0.8807970779778823, 0.8807970779778823, 0.8807970779778823]\n",
      "[0.5, 0.5] [1, 0]\n",
      "0.6931471805599453\n",
      "-0.0\n",
      "loss: 0.6931471805599453\n",
      "dldo: [-0.5, 0.5]\n",
      "dldv: [[-0.44039853898894116, 0.44039853898894116], [-0.44039853898894116, 0.44039853898894116], [-0.44039853898894116, 0.44039853898894116]]\n",
      "dldh: [0.0, 0.0, 0.0]\n",
      "dldc: [-0.5, 0.5]\n",
      "dldk: [0.0, 0.0, 0.0]\n",
      "dldw: [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
      "dldb: [0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# mlp = MLP()\n",
    "# lr = 0.1\n",
    "# loss_arr = []\n",
    "\n",
    "# dldh = [0.0, 0.0, 0.0]\n",
    "# dldk = [0.0, 0.0, 0.0]\n",
    "# dldo = [0.0, 0.0]\n",
    "# dldy = [0.0, 0.0]\n",
    "\n",
    "# dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "# dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "# dldb = [0.0, 0.0, 0.0]\n",
    "# dldc = [0.0, 0.0]\n",
    "     \n",
    "# w_weights = [[1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]]\n",
    "# b_weights = [0.0, 0.0, 0.0] \n",
    "# v_weights = [[1.0, 1.0], [-1.0, -1.0], [-1.0, -1.0]]  # rand_weights(3, 2) # # \n",
    "# c_weights = [0.0, 0.0]\n",
    "       \n",
    "# for i in range(1):\n",
    "#     x_inputs = [1, -1]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     y_outputs = mlp.forward(x_inputs, w_weights, b_weights, v_weights, c_weights)\n",
    "#     loss = mlp.loss(y_outputs, t_targets)\n",
    "    \n",
    "#     print(loss)\n",
    "    \n",
    "#     dldw, dldb, dldv, dldc = mlp.backward(y_outputs, t_targets)\n",
    "    \n",
    "#     mlp.sgd(lr, w_weights, b_weights, v_weights, c_weights, dldw, dldb, dldv, dldc)\n",
    "    \n",
    "#     loss_arr.append(loss)\n",
    "    \n",
    "    \n",
    "a_learning_rate = 1e-4\n",
    "mlp = MLP()\n",
    "mlp.set_learning_rate(a_learning_rate)\n",
    "\n",
    "losses = []\n",
    "epochs = 5\n",
    "\n",
    "dldh = [0.0, 0.0, 0.0]\n",
    "dldk = [0.0, 0.0, 0.0]\n",
    "dldo = [0.0, 0.0]\n",
    "dldy = [0.0, 0.0]\n",
    "\n",
    "dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "dldb = [0.0, 0.0, 0.0]\n",
    "dldc = [0.0, 0.0]\n",
    "     \n",
    "w_weights = [[1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]]\n",
    "b_weights = [0.0, 0.0, 0.0] \n",
    "v_weights = [[1.0, 1.0], [-1.0, -1.0], [-1.0, -1.0]]  # rand_weights(3, 2) # # \n",
    "c_weights = [0.0, 0.0]\n",
    "\n",
    "for j in range(1):\n",
    "    loss_avg = []\n",
    "    \n",
    "    dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "    dldb = [0.0, 0.0, 0.0]\n",
    "    dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "    dldc = [0.0, 0.0]\n",
    "    \n",
    "    for i in range(1):\n",
    "        t_targets = target_arr(num_cls=2, t=0)\n",
    "        \n",
    "        x_inputs = [1, -1]\n",
    "        \n",
    "        y_outputs, h_hidden = mlp.forward(x_inputs, w_weights, b_weights, v_weights, c_weights)\n",
    "        print('yes', y_outputs, h_hidden)\n",
    "        loss = mlp.loss(y_outputs, t_targets)\n",
    "        \n",
    "        w_pri, b_pri, v_pri, c_pri = mlp.backward(y_outputs, t_targets, h_hidden, v_weights, x_inputs, dldw, dldb, dldv, dldc)\n",
    "        \n",
    "        dldw += w_pri\n",
    "        dldb += b_pri\n",
    "        dldv += v_pri\n",
    "        dldc += c_pri\n",
    "        \n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            losses.append(loss)\n",
    "            \n",
    "    v_weights, w_weights, c_weights, b_weights = mlp.sgd(a_learning_rate, w_weights, b_weights, v_weights, c_weights, dldw, dldb, dldv, dldc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/SrBM8AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA2cElEQVR4nO3de1hV1b7/8c8CZAEqoKgsUdC8bMVL2tYgtLaVFJaVmB6N7QXdnuzibeflqOUt220rLU0t3Z6zy8fSNNtlZabhrYviDc0rcGznXYHMABUFhPn7o5/rtBSHQCAsfb+eZz66xhxjzu+YD8rnmXOstWyWZVkCAABAkTwqugAAAIDKjLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsATAbQ0YMEANGzYs1dgpU6bIZrOVbUHF9HvqBnDjEZYAlDmbzVasbePGjRVdKgBcl43vhgNQ1t5//32X14sWLVJCQoLee+89l/YHHnhAwcHBpT5Pfn6+CgsLZbfbSzz20qVLunTpknx8fEp9/tIaMGCANm7cqMOHD9/wcwMoOa+KLgDAzadv374ur7ds2aKEhISr2q+Uk5MjPz+/Yp+nSpUqpapPkry8vOTlxX+BAK6Px3AAKsS9996rVq1aKSkpSX/605/k5+en559/XpL06aefqmvXrgoJCZHdblfjxo310ksvqaCgwOUYV679OXz4sGw2m2bMmKEFCxaocePGstvtuvPOO7V9+3aXsUWtWbLZbBo6dKhWrFihVq1ayW63q2XLllq9evVV9W/cuFHt27eXj4+PGjdurH/84x+/ax3U+fPnNWrUKIWGhsput6tZs2aaMWOGrrz5n5CQoLvvvluBgYGqVq2amjVr5rxul82ZM0ctW7aUn5+fatSoofbt22vJkiWlqgsAd5YAVKCff/5ZDz30kJ544gn17dvX+Uhu4cKFqlatmkaOHKlq1app/fr1mjRpkrKzszV9+vTrHnfJkiU6e/asnnrqKdlsNr322mt6/PHH9eOPP173btR3332njz/+WM8++6yqV6+u2bNnq0ePHjp69KiCgoIkSbt27VKXLl1Ut25dvfjiiyooKNDUqVNVu3btUl0Hy7L02GOPacOGDRo0aJDatm2rNWvWaMyYMTpx4oRmzpwpSdq/f78eeeQR3X777Zo6darsdrt++OEHbdq0yXms//7v/9bw4cPVs2dPjRgxQhcvXtSePXu0detW/fnPfy5VfcAtzwKAcjZkyBDryv9uOnXqZEmy5s+ff1X/nJycq9qeeuopy8/Pz7p48aKzLT4+3mrQoIHz9aFDhyxJVlBQkHXmzBln+6effmpJsj7//HNn2+TJk6+qSZLl7e1t/fDDD8623bt3W5KsOXPmONseffRRy8/Pzzpx4oSz7eDBg5aXl9dVxyzKlXWvWLHCkmT97W9/c+nXs2dPy2azOeuZOXOmJcn66aefrnnsbt26WS1btrxuDQCKj8dwACqM3W7XwIEDr2r39fV1/v3s2bM6ffq07rnnHuXk5CglJeW6x+3du7dq1KjhfH3PPfdIkn788cfrjo2Ojlbjxo2dr2+//Xb5+/s7xxYUFGjt2rWKjY1VSEiIs1+TJk300EMPXff4RVm1apU8PT01fPhwl/ZRo0bJsix9+eWXkqTAwEBJvz6mLCwsLPJYgYGBOn78+FWPHQGUHmEJQIWpV6+evL29r2rfv3+/unfvroCAAPn7+6t27drOxeFZWVnXPW5YWJjL68vB6Zdffinx2MvjL4/NyMjQhQsX1KRJk6v6FdVWHEeOHFFISIiqV6/u0h4eHu7cL/0aAjt27Kj//M//VHBwsJ544gl9+OGHLsFp7NixqlatmiIiItS0aVMNGTLE5TEdgJIjLAGoML+9g3RZZmamOnXqpN27d2vq1Kn6/PPPlZCQoFdffVWSrnlH5bc8PT2LbLeK8Ukpv2dsefP19dU333yjtWvXql+/ftqzZ4969+6tBx54wLn4PTw8XKmpqVq6dKnuvvtu/etf/9Ldd9+tyZMnV3D1gPsiLAGoVDZu3Kiff/5ZCxcu1IgRI/TII48oOjra5bFaRapTp458fHz0ww8/XLWvqLbiaNCggU6ePKmzZ8+6tF9+5NigQQNnm4eHhzp37qw33nhDBw4c0Msvv6z169drw4YNzj5Vq1ZV79699e677+ro0aPq2rWrXn75ZV28eLFU9QG3OsISgErl8p2d397JycvL09tvv11RJbnw9PRUdHS0VqxYoZMnTzrbf/jhB+faopJ6+OGHVVBQoLlz57q0z5w5UzabzbkW6syZM1eNbdu2rSQpNzdX0q/vMPwtb29vtWjRQpZlKT8/v1T1Abc6PjoAQKXSoUMH1ahRQ/Hx8Ro+fLhsNpvee++9SvEY7LIpU6boq6++UseOHfXMM884g06rVq30/fffl/h4jz76qO677z698MILOnz4sNq0aaOvvvpKn376qf761786F5xPnTpV33zzjbp27aoGDRooIyNDb7/9turXr6+7775bkvTggw/K4XCoY8eOCg4OVnJysubOnauuXbtetSYKQPEQlgBUKkFBQVq5cqVGjRqlCRMmqEaNGurbt686d+6smJiYii5PktSuXTt9+eWXGj16tCZOnKjQ0FBNnTpVycnJxXq33pU8PDz02WefadKkSVq2bJneffddNWzYUNOnT9eoUaOc/R577DEdPnxY77zzjk6fPq1atWqpU6dOevHFFxUQECBJeuqpp7R48WK98cYbOnfunOrXr6/hw4drwoQJZTZ/4FbDd8MBQBmJjY3V/v37dfDgwYouBUAZYs0SAJTChQsXXF4fPHhQq1at0r333lsxBQEoN9xZAoBSqFu3rgYMGKBGjRrpyJEjmjdvnnJzc7Vr1y41bdq0ossDUIZYswQApdClSxd98MEHSktLk91uV1RUlP7+978TlICbEHeWAAAADFizBAAAYEBYAgAAMGDNUhkoLCzUyZMnVb16ddlstoouBwAAFINlWTp79qxCQkLk4XHt+0eEpTJw8uRJhYaGVnQZAACgFI4dO6b69etfcz9hqQxc/gqBY8eOyd/fv4KrAQAAxZGdna3Q0NDrfhUQYakMXH705u/vT1gCAMDNXG8JDQu8AQAADAhLAAAABoQlAAAAA9YsAQBuCoWFhcrLy6voMlCJVKlSRZ6enr/7OIQlAIDby8vL06FDh1RYWFjRpaCSCQwMlMPh+F2fg0hYAgC4NcuydOrUKXl6eio0NNT44YK4dViWpZycHGVkZEiS6tatW+pjEZYAAG7t0qVLysnJUUhIiPz8/Cq6HFQivr6+kqSMjAzVqVOn1I/kiN8AALdWUFAgSfL29q7gSlAZXQ7Q+fn5pT4GYQkAcFPguzlRlLL4uSAsAQAAGBCWAAC4STRs2FCzZs0qdv+NGzfKZrMpMzOz3GqSpIULFyowMLBcz1GeCEsAANxgNpvNuE2ZMqVUx92+fbsGDx5c7P4dOnTQqVOnFBAQUKrz3Sp4NxwAADfYqVOnnH9ftmyZJk2apNTUVGdbtWrVnH+3LEsFBQXy8rr+r+zatWuXqA5vb285HI4SjbkVcWcJAIAbzOFwOLeAgADZbDbn65SUFFWvXl1ffvml2rVrJ7vdru+++07//ve/1a1bNwUHB6tatWq68847tXbtWpfjXvkYzmaz6X/+53/UvXt3+fn5qWnTpvrss8+c+698DHf5cdmaNWsUHh6uatWqqUuXLi7h7tKlSxo+fLgCAwMVFBSksWPHKj4+XrGxsSW6BvPmzVPjxo3l7e2tZs2a6b333nPusyxLU6ZMUVhYmOx2u0JCQjR8+HDn/rfffltNmzaVj4+PgoOD1bNnzxKdu6QISwCAm4plWTqfd75CNsuyymwe48aN0yuvvKLk5GTdfvvtOnfunB5++GGtW7dOu3btUpcuXfToo4/q6NGjxuO8+OKL6tWrl/bs2aOHH35Yffr00ZkzZ67ZPycnRzNmzNB7772nb775RkePHtXo0aOd+1999VUtXrxY7777rjZt2qTs7GytWLGiRHP75JNPNGLECI0aNUr79u3TU089pYEDB2rDhg2SpH/961+aOXOm/vGPf+jgwYNasWKFWrduLUnasWOHhg8frqlTpyo1NVWrV6/Wn/70pxKdv6R4DAcAuKnk5Oeo2rRq1+9YDs6NP6eq3lXL5FhTp07VAw884Hxds2ZNtWnTxvn6pZde0ieffKLPPvtMQ4cOveZxBgwYoLi4OEnS3//+d82ePVvbtm1Tly5diuyfn5+v+fPnq3HjxpKkoUOHaurUqc79c+bM0fjx49W9e3dJ0ty5c7Vq1aoSzW3GjBkaMGCAnn32WUnSyJEjtWXLFs2YMUP33Xefjh49KofDoejoaFWpUkVhYWGKiIiQJB09elRVq1bVI488ourVq6tBgwa64447SnT+kuLOEgAAlVD79u1dXp87d06jR49WeHi4AgMDVa1aNSUnJ1/3ztLtt9/u/HvVqlXl7+/v/AqQovj5+TmDkvTr14Rc7p+VlaX09HRncJEkT09PtWvXrkRzS05OVseOHV3aOnbsqOTkZEnSf/zHf+jChQtq1KiRnnzySX3yySe6dOmSJOmBBx5QgwYN1KhRI/Xr10+LFy9WTk5Oic5fUtxZAgDcVPyq+Onc+HMVdu6yUrWq6x2q0aNHKyEhQTNmzFCTJk3k6+urnj17Ki8vz3icKlWquLy22WzGLxwuqn9ZPl4sjtDQUKWmpmrt2rVKSEjQs88+q+nTp+vrr79W9erVtXPnTm3cuFFfffWVJk2apClTpmj79u3l9vEE3FkCANxUbDabqnpXrZCtPD9FfNOmTRowYIC6d++u1q1by+Fw6PDhw+V2vqIEBAQoODhY27dvd7YVFBRo586dJTpOeHi4Nm3a5NK2adMmtWjRwvna19dXjz76qGbPnq2NGzcqMTFRe/fulSR5eXkpOjpar732mvbs2aPDhw9r/fr1v2NmZtxZAgDADTRt2lQff/yxHn30UdlsNk2cONF4h6i8DBs2TNOmTVOTJk3UvHlzzZkzR7/88kuJguKYMWPUq1cv3XHHHYqOjtbnn3+ujz/+2PnuvoULF6qgoECRkZHy8/PT+++/L19fXzVo0EArV67Ujz/+qD/96U+qUaOGVq1apcLCQjVr1qy8pkxYAgDAHbzxxhv6y1/+og4dOqhWrVoaO3assrOzb3gdY8eOVVpamvr37y9PT08NHjxYMTEx8vT0LPYxYmNj9eabb2rGjBkaMWKEbrvtNr377ru69957JUmBgYF65ZVXNHLkSBUUFKh169b6/PPPFRQUpMDAQH388ceaMmWKLl68qKZNm+qDDz5Qy5Yty2nGks260Q8ib0LZ2dkKCAhQVlaW/P39K7ocALilXLx4UYcOHdJtt90mHx+fii7nllNYWKjw8HD16tVLL730UkWXcxXTz0dxf39zZwkAABTbkSNH9NVXX6lTp07Kzc3V3LlzdejQIf35z3+u6NLKDQu8AQBAsXl4eGjhwoW688471bFjR+3du1dr165VeHh4RZdWbrizBAAAii00NPSqd7Ld7LizBAAAYEBYAgDcFHi/EopSFj8XhCUAgFu7/Jb1632SNW5Nl78K5cpPJi8J1iwBANyal5eX/Pz89NNPP6lKlSry8OA+AH69o5STk6OMjAwFBgaW6HOgrkRYAgC4NZvNprp16+rQoUM6cuRIRZeDSiYwMFAOh+N3HYOwBABwe97e3mratCmP4uCiSpUqv+uO0mWEJQDATcHDw4NP8Ea54MEuAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGDgdmHprbfeUsOGDeXj46PIyEht27bN2H/58uVq3ry5fHx81Lp1a61ateqafZ9++mnZbDbNmjWrjKsGAADuyq3C0rJlyzRy5EhNnjxZO3fuVJs2bRQTE6OMjIwi+2/evFlxcXEaNGiQdu3apdjYWMXGxmrfvn1X9f3kk0+0ZcsWhYSElPc0AACAG3GrsPTGG2/oySef1MCBA9WiRQvNnz9ffn5+euedd4rs/+abb6pLly4aM2aMwsPD9dJLL+mPf/yj5s6d69LvxIkTGjZsmBYvXqwqVarciKkAAAA34TZhKS8vT0lJSYqOjna2eXh4KDo6WomJiUWOSUxMdOkvSTExMS79CwsL1a9fP40ZM0YtW7Ysn+IBAIDb8qroAorr9OnTKigoUHBwsEt7cHCwUlJSihyTlpZWZP+0tDTn61dffVVeXl4aPnx4sWvJzc1Vbm6u83V2dnaxxwIAAPfiNneWykNSUpLefPNNLVy4UDabrdjjpk2bpoCAAOcWGhpajlUCAICK5DZhqVatWvL09FR6erpLe3p6uhwOR5FjHA6Hsf+3336rjIwMhYWFycvLS15eXjpy5IhGjRqlhg0bXrOW8ePHKysry7kdO3bs900OAABUWm4Tlry9vdWuXTutW7fO2VZYWKh169YpKiqqyDFRUVEu/SUpISHB2b9fv37as2ePvv/+e+cWEhKiMWPGaM2aNdesxW63y9/f32UDAAA3J7dZsyRJI0eOVHx8vNq3b6+IiAjNmjVL58+f18CBAyVJ/fv3V7169TRt2jRJ0ogRI9SpUye9/vrr6tq1q5YuXaodO3ZowYIFkqSgoCAFBQW5nKNKlSpyOBxq1qzZjZ0cAAColNwqLPXu3Vs//fSTJk2apLS0NLVt21arV692LuI+evSoPDz+72ZZhw4dtGTJEk2YMEHPP/+8mjZtqhUrVqhVq1YVNQUAAOBmbJZlWRVdhLvLzs5WQECAsrKyeCQHAICbKO7vb7dZswQAAFARCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABi4XVh666231LBhQ/n4+CgyMlLbtm0z9l++fLmaN28uHx8ftW7dWqtWrXLuy8/P19ixY9W6dWtVrVpVISEh6t+/v06ePFne0wAAAG7CrcLSsmXLNHLkSE2ePFk7d+5UmzZtFBMTo4yMjCL7b968WXFxcRo0aJB27dql2NhYxcbGat++fZKknJwc7dy5UxMnTtTOnTv18ccfKzU1VY899tiNnBYAAKjEbJZlWRVdRHFFRkbqzjvv1Ny5cyVJhYWFCg0N1bBhwzRu3Lir+vfu3Vvnz5/XypUrnW133XWX2rZtq/nz5xd5ju3btysiIkJHjhxRWFhYserKzs5WQECAsrKy5O/vX4qZAQCAG624v7/d5s5SXl6ekpKSFB0d7Wzz8PBQdHS0EhMTixyTmJjo0l+SYmJirtlfkrKysmSz2RQYGFgmdQMAAPfmVdEFFNfp06dVUFCg4OBgl/bg4GClpKQUOSYtLa3I/mlpaUX2v3jxosaOHau4uDhjwszNzVVubq7zdXZ2dnGnAQAA3Izb3Fkqb/n5+erVq5csy9K8efOMfadNm6aAgADnFhoaeoOqBAAAN5rbhKVatWrJ09NT6enpLu3p6elyOBxFjnE4HMXqfzkoHTlyRAkJCddddzR+/HhlZWU5t2PHjpViRgAAwB24TVjy9vZWu3bttG7dOmdbYWGh1q1bp6ioqCLHREVFufSXpISEBJf+l4PSwYMHtXbtWgUFBV23FrvdLn9/f5cNAADcnNxmzZIkjRw5UvHx8Wrfvr0iIiI0a9YsnT9/XgMHDpQk9e/fX/Xq1dO0adMkSSNGjFCnTp30+uuvq2vXrlq6dKl27NihBQsWSPo1KPXs2VM7d+7UypUrVVBQ4FzPVLNmTXl7e1fMRAEAQKXhVmGpd+/e+umnnzRp0iSlpaWpbdu2Wr16tXMR99GjR+Xh8X83yzp06KAlS5ZowoQJev7559W0aVOtWLFCrVq1kiSdOHFCn332mSSpbdu2LufasGGD7r333hsyLwAAUHm51ecsVVZ8zhIAAO7npvucJQAAgIpAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBQqrB07NgxHT9+3Pl627Zt+utf/6oFCxaUWWEAAACVQanC0p///Gdt2LBBkpSWlqYHHnhA27Zt0wsvvKCpU6eWaYEAAAAVqVRhad++fYqIiJAkffjhh2rVqpU2b96sxYsXa+HChWVZHwAAQIUqVVjKz8+X3W6XJK1du1aPPfaYJKl58+Y6depU2VUHAABQwUoVllq2bKn58+fr22+/VUJCgrp06SJJOnnypIKCgsq0QAAAgIpUqrD06quv6h//+IfuvfdexcXFqU2bNpKkzz77zPl4DgAA4GZgsyzLKs3AgoICZWdnq0aNGs62w4cPy8/PT3Xq1CmzAt1Bdna2AgIClJWVJX9//4ouBwAAFENxf3+X6s7ShQsXlJub6wxKR44c0axZs5SamnrLBSUAAHBzK1VY6tatmxYtWiRJyszMVGRkpF5//XXFxsZq3rx5ZVrgld566y01bNhQPj4+ioyM1LZt24z9ly9frubNm8vHx0etW7fWqlWrXPZblqVJkyapbt268vX1VXR0tA4ePFieUwAAAG6kVGFp586duueeeyRJH330kYKDg3XkyBEtWrRIs2fPLtMCf2vZsmUaOXKkJk+erJ07d6pNmzaKiYlRRkZGkf03b96suLg4DRo0SLt27VJsbKxiY2O1b98+Z5/XXntNs2fP1vz587V161ZVrVpVMTExunjxYrnNAwAAuI9SrVny8/NTSkqKwsLC1KtXL7Vs2VKTJ0/WsWPH1KxZM+Xk5JRHrYqMjNSdd96puXPnSpIKCwsVGhqqYcOGady4cVf17927t86fP6+VK1c62+666y61bdtW8+fPl2VZCgkJ0ahRozR69GhJUlZWloKDg7Vw4UI98cQTxaqLNUsAALifcl2z1KRJE61YsULHjh3TmjVr9OCDD0qSMjIyyi0s5OXlKSkpSdHR0c42Dw8PRUdHKzExscgxiYmJLv0lKSYmxtn/0KFDSktLc+kTEBCgyMjIax5TknJzc5Wdne2yAQCAm1OpwtKkSZM0evRoNWzYUBEREYqKipIkffXVV7rjjjvKtMDLTp8+rYKCAgUHB7u0BwcHKy0trcgxaWlpxv6X/yzJMSVp2rRpCggIcG6hoaElng8AAHAPpQpLPXv21NGjR7Vjxw6tWbPG2d65c2fNnDmzzIqrrMaPH6+srCznduzYsYouCQAAlBOv0g50OBxyOBw6fvy4JKl+/frl+oGUtWrVkqenp9LT013a09PT5XA4rlmjqf/lP9PT01W3bl2XPm3btr1mLXa73fl1LwAA4OZWqjtLhYWFmjp1qgICAtSgQQM1aNBAgYGBeumll1RYWFjWNUqSvL291a5dO61bt86ljnXr1jkfA14pKirKpb8kJSQkOPvfdtttcjgcLn2ys7O1devWax4TAADcWkp1Z+mFF17QP//5T73yyivq2LGjJOm7777TlClTdPHiRb388stlWuRlI0eOVHx8vNq3b6+IiAjNmjVL58+f18CBAyVJ/fv3V7169TRt2jRJ0ogRI9SpUye9/vrr6tq1q5YuXaodO3ZowYIFkiSbzaa//vWv+tvf/qamTZvqtttu08SJExUSEqLY2NhymQMAAHAzVinUrVvX+vTTT69qX7FihRUSElKaQxbbnDlzrLCwMMvb29uKiIiwtmzZ4tzXqVMnKz4+3qX/hx9+aP3hD3+wvL29rZYtW1pffPGFy/7CwkJr4sSJVnBwsGW3263OnTtbqampJaopKyvLkmRlZWWVel4AAODGKu7v71J9zpKPj4/27NmjP/zhDy7tqampatu2rS5cuFBGUc498DlLAAC4n3L9nKU2bdo4Pxjyt+bOnavbb7+9NIcEAAColEq1Zum1115T165dtXbtWudC6MTERB07duyq714DAABwZ6W6s9SpUyf97//+r7p3767MzExlZmbq8ccf1/79+/Xee++VdY0AAAAVplRrlq5l9+7d+uMf/6iCgoKyOqRbYM0SAADup1zXLAEAANwqCEsAAAAGhCUAAACDEr0b7vHHHzfuz8zM/D21AAAAVDolCksBAQHX3d+/f//fVRAAAEBlUqKw9O6775ZXHQAAAJUSa5YAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABg4DZh6cyZM+rTp4/8/f0VGBioQYMG6dy5c8YxFy9e1JAhQxQUFKRq1aqpR48eSk9Pd+7fvXu34uLiFBoaKl9fX4WHh+vNN98s76kAAAA34jZhqU+fPtq/f78SEhK0cuVKffPNNxo8eLBxzHPPPafPP/9cy5cv19dff62TJ0/q8ccfd+5PSkpSnTp19P7772v//v164YUXNH78eM2dO7e8pwMAANyEzbIsq6KLuJ7k5GS1aNFC27dvV/v27SVJq1ev1sMPP6zjx48rJCTkqjFZWVmqXbu2lixZop49e0qSUlJSFB4ersTERN11111FnmvIkCFKTk7W+vXri11fdna2AgIClJWVJX9//1LMEAAA3GjF/f3tFneWEhMTFRgY6AxKkhQdHS0PDw9t3bq1yDFJSUnKz89XdHS0s6158+YKCwtTYmLiNc+VlZWlmjVrGuvJzc1Vdna2ywYAAG5ObhGW0tLSVKdOHZc2Ly8v1axZU2lpadcc4+3trcDAQJf24ODga47ZvHmzli1bdt3He9OmTVNAQIBzCw0NLf5kAACAW6nQsDRu3DjZbDbjlpKSckNq2bdvn7p166bJkyfrwQcfNPYdP368srKynNuxY8duSI0AAODG86rIk48aNUoDBgww9mnUqJEcDocyMjJc2i9duqQzZ87I4XAUOc7hcCgvL0+ZmZkud5fS09OvGnPgwAF17txZgwcP1oQJE65bt91ul91uv24/AADg/io0LNWuXVu1a9e+br+oqChlZmYqKSlJ7dq1kyStX79ehYWFioyMLHJMu3btVKVKFa1bt049evSQJKWmpuro0aOKiopy9tu/f7/uv/9+xcfH6+WXXy6DWQEAgJuJW7wbTpIeeughpaena/78+crPz9fAgQPVvn17LVmyRJJ04sQJde7cWYsWLVJERIQk6ZlnntGqVau0cOFC+fv7a9iwYZJ+XZsk/fro7f7771dMTIymT5/uPJenp2exQtxlvBsOAAD3U9zf3xV6Z6kkFi9erKFDh6pz587y8PBQjx49NHv2bOf+/Px8paamKicnx9k2c+ZMZ9/c3FzFxMTo7bffdu7/6KOP9NNPP+n999/X+++/72xv0KCBDh8+fEPmBQAAKje3ubNUmXFnCQAA93NTfc4SAABARSEsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABg4DZh6cyZM+rTp4/8/f0VGBioQYMG6dy5c8YxFy9e1JAhQxQUFKRq1aqpR48eSk9PL7Lvzz//rPr168tmsykzM7McZgAAANyR24SlPn36aP/+/UpISNDKlSv1zTffaPDgwcYxzz33nD7//HMtX75cX3/9tU6ePKnHH3+8yL6DBg3S7bffXh6lAwAAN2azLMuq6CKuJzk5WS1atND27dvVvn17SdLq1av18MMP6/jx4woJCblqTFZWlmrXrq0lS5aoZ8+ekqSUlBSFh4crMTFRd911l7PvvHnztGzZMk2aNEmdO3fWL7/8osDAwGLXl52drYCAAGVlZcnf3//3TRYAANwQxf397RZ3lhITExUYGOgMSpIUHR0tDw8Pbd26tcgxSUlJys/PV3R0tLOtefPmCgsLU2JiorPtwIEDmjp1qhYtWiQPj+JdjtzcXGVnZ7tsAADg5uQWYSktLU116tRxafPy8lLNmjWVlpZ2zTHe3t5X3SEKDg52jsnNzVVcXJymT5+usLCwYtczbdo0BQQEOLfQ0NCSTQgAALiNCg1L48aNk81mM24pKSnldv7x48crPDxcffv2LfG4rKws53bs2LFyqhAAAFQ0r4o8+ahRozRgwABjn0aNGsnhcCgjI8Ol/dKlSzpz5owcDkeR4xwOh/Ly8pSZmelydyk9Pd05Zv369dq7d68++ugjSdLl5Vu1atXSCy+8oBdffLHIY9vtdtnt9uJMEQAAuLkKDUu1a9dW7dq1r9svKipKmZmZSkpKUrt27ST9GnQKCwsVGRlZ5Jh27dqpSpUqWrdunXr06CFJSk1N1dGjRxUVFSVJ+te//qULFy44x2zfvl1/+ctf9O2336px48a/d3oAAOAmUKFhqbjCw8PVpUsXPfnkk5o/f77y8/M1dOhQPfHEE853wp04cUKdO3fWokWLFBERoYCAAA0aNEgjR45UzZo15e/vr2HDhikqKsr5TrgrA9Hp06ed5yvJu+EAAMDNyy3CkiQtXrxYQ4cOVefOneXh4aEePXpo9uzZzv35+flKTU1VTk6Os23mzJnOvrm5uYqJidHbb79dEeUDAAA35Rafs1TZ8TlLAAC4n5vqc5YAAAAqCmEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAQAAGBCWAAAADAhLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAGhCUAAAADwhIAAIABYQkAAMCAsAQAAGBAWAIAADAgLAEAABgQlgAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYOBV0QXcDCzLkiRlZ2dXcCUAAKC4Lv/evvx7/FoIS2Xg7NmzkqTQ0NAKrgQAAJTU2bNnFRAQcM39Nut6cQrXVVhYqJMnT6p69eqy2WwVXU6Fys7OVmhoqI4dOyZ/f/+KLuemxXW+cbjWNwbX+cbgOruyLEtnz55VSEiIPDyuvTKJO0tlwMPDQ/Xr16/oMioVf39//iHeAFznG4drfWNwnW8MrvP/Md1RuowF3gAAAAaEJQAAAAPCEsqU3W7X5MmTZbfbK7qUmxrX+cbhWt8YXOcbg+tcOizwBgAAMODOEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsocTOnDmjPn36yN/fX4GBgRo0aJDOnTtnHHPx4kUNGTJEQUFBqlatmnr06KH09PQi+/7888+qX7++bDabMjMzy2EG7qE8rvPu3bsVFxen0NBQ+fr6Kjw8XG+++WZ5T6VSeeutt9SwYUP5+PgoMjJS27ZtM/Zfvny5mjdvLh8fH7Vu3VqrVq1y2W9ZliZNmqS6devK19dX0dHROnjwYHlOwS2U5XXOz8/X2LFj1bp1a1WtWlUhISHq37+/Tp48Wd7TqPTK+uf5t55++mnZbDbNmjWrjKt2QxZQQl26dLHatGljbdmyxfr222+tJk2aWHFxccYxTz/9tBUaGmqtW7fO2rFjh3XXXXdZHTp0KLJvt27drIceesiSZP3yyy/lMAP3UB7X+Z///Kc1fPhwa+PGjda///1v67333rN8fX2tOXPmlPd0KoWlS5da3t7e1jvvvGPt37/fevLJJ63AwEArPT29yP6bNm2yPD09rddee806cOCANWHCBKtKlSrW3r17nX1eeeUVKyAgwFqxYoW1e/du67HHHrNuu+0268KFCzdqWpVOWV/nzMxMKzo62lq2bJmVkpJiJSYmWhEREVa7du1u5LQqnfL4eb7s448/ttq0aWOFhIRYM2fOLOeZVH6EJZTIgQMHLEnW9u3bnW1ffvmlZbPZrBMnThQ5JjMz06pSpYq1fPlyZ1tycrIlyUpMTHTp+/bbb1udOnWy1q1bd0uHpfK+zr/17LPPWvfdd1/ZFV+JRUREWEOGDHG+LigosEJCQqxp06YV2b9Xr15W165dXdoiIyOtp556yrIsyyosLLQcDoc1ffp05/7MzEzLbrdbH3zwQTnMwD2U9XUuyrZt2yxJ1pEjR8qmaDdUXtf5+PHjVr169ax9+/ZZDRo0ICxZlsVjOJRIYmKiAgMD1b59e2dbdHS0PDw8tHXr1iLHJCUlKT8/X9HR0c625s2bKywsTImJic62AwcOaOrUqVq0aJHxCw1vBeV5na+UlZWlmjVrll3xlVReXp6SkpJcro+Hh4eio6OveX0SExNd+ktSTEyMs/+hQ4eUlpbm0icgIECRkZHGa34zK4/rXJSsrCzZbDYFBgaWSd3upryuc2Fhofr166cxY8aoZcuW5VO8G7q1fyOhxNLS0lSnTh2XNi8vL9WsWVNpaWnXHOPt7X3Vf2rBwcHOMbm5uYqLi9P06dMVFhZWLrW7k/K6zlfavHmzli1bpsGDB5dJ3ZXZ6dOnVVBQoODgYJd20/VJS0sz9r/8Z0mOebMrj+t8pYsXL2rs2LGKi4u7Zb8Mtryu86uvviovLy8NHz687It2Y4QlSJLGjRsnm81m3FJSUsrt/OPHj1d4eLj69u1bbueoDCr6Ov/Wvn371K1bN02ePFkPPvjgDTkn8Hvl5+erV69esixL8+bNq+hybipJSUl68803tXDhQtlstooup1LxqugCUDmMGjVKAwYMMPZp1KiRHA6HMjIyXNovXbqkM2fOyOFwFDnO4XAoLy9PmZmZLnc90tPTnWPWr1+vvXv36qOPPpL06zuMJKlWrVp64YUX9OKLL5ZyZpVLRV/nyw4cOKDOnTtr8ODBmjBhQqnm4m5q1aolT0/Pq96FWdT1uczhcBj7X/4zPT1ddevWdenTtm3bMqzefZTHdb7sclA6cuSI1q9ff8veVZLK5zp/++23ysjIcLm7X1BQoFGjRmnWrFk6fPhw2U7CnVT0oim4l8sLj3fs2OFsW7NmTbEWHn/00UfOtpSUFJeFxz/88IO1d+9e5/bOO+9YkqzNmzdf850dN7Pyus6WZVn79u2z6tSpY40ZM6b8JlBJRUREWEOHDnW+LigosOrVq2dcEPvII4+4tEVFRV21wHvGjBnO/VlZWSzwLuPrbFmWlZeXZ8XGxlotW7a0MjIyyqdwN1PW1/n06dMu/w/v3bvXCgkJscaOHWulpKSU30TcAGEJJdalSxfrjjvusLZu3Wp99913VtOmTV3e0n78+HGrWbNm1tatW51tTz/9tBUWFmatX7/e2rFjhxUVFWVFRUVd8xwbNmy4pd8NZ1nlc5337t1r1a5d2+rbt6916tQp53ar/PJZunSpZbfbrYULF1oHDhywBg8ebAUGBlppaWmWZVlWv379rHHjxjn7b9q0yfLy8rJmzJhhJScnW5MnTy7yowMCAwOtTz/91NqzZ4/VrVs3PjqgjK9zXl6e9dhjj1n169e3vv/+e5ef3dzc3AqZY2VQHj/PV+LdcL8iLKHEfv75ZysuLs6qVq2a5e/vbw0cONA6e/asc/+hQ4csSdaGDRucbRcuXLCeffZZq0aNGpafn5/VvXt369SpU9c8B2GpfK7z5MmTLUlXbQ0aNLiBM6tYc+bMscLCwixvb28rIiLC2rJli3Nfp06drPj4eJf+H374ofWHP/zB8vb2tlq2bGl98cUXLvsLCwutiRMnWsHBwZbdbrc6d+5spaam3oipVGpleZ0v/6wXtf325/9WVNY/z1ciLP3KZln/f3EIAAAArsK74QAAAAwISwAAAAaEJQAAAAPCEgAAgAFhCQAAwICwBAAAYEBYAgAAMCAsAbhlHD58WDabTd9//325nWPAgAGKjY0tt+MDuPEISwDcxoABA2Sz2a7aunTpUqzxoaGhOnXqlFq1alXOlQK4mXhVdAEAUBJdunTRu+++69Jmt9uLNdbT0/Oa38gOANfCnSUAbsVut8vhcLhsNWrUkCTZbDbNmzdPDz30kHx9fdWoUSN99NFHzrFXPob75Zdf1KdPH9WuXVu+vr5q2rSpSxDbu3ev7r//fvn6+iooKEiDBw/WuXPnnPsLCgo0cuRIBQYGKigoSP/1X/+lK79BqrCwUNOmTdNtt90mX19ftWnTxqWm69UAoOIRlgDcVCZOnKgePXpo9+7d6tOnj5544gklJydfs++BAwf05ZdfKjk5WfPmzVOtWrUkSefPn1dMTIxq1Kih7du3a/ny5Vq7dq2GDh3qHP/6669r4cKFeuedd/Tdd9/pzJkz+uSTT1zOMW3aNC1atEjz58/X/v379dxzz6lv3776+uuvr1sDgEqigr/IFwCKLT4+3vL09LSqVq3qsr388suWZVmWJOvpp592GRMZGWk988wzlmX937fX79q1y7Isy3r00UetgQMHFnmuBQsWWDVq1LDOnTvnbPviiy8sDw8PKy0tzbIsy6pbt6712muvOffn5+db9evXt7p162ZZlmVdvHjR8vPzszZv3uxy7EGDBllxcXHXrQFA5cCaJQBu5b777tO8efNc2mrWrOn8e1RUlMu+qKioa7777ZlnnlGPHj20c+dOPfjgg4qNjVWHDh0kScnJyWrTpo2qVq3q7N+xY0cVFhYqNTVVPj4+OnXqlCIjI537vby81L59e+ejuB9++EE5OTl64IEHXM6bl5enO+6447o1AKgcCEsA3ErVqlXVpEmTMjnWQw89pCNHjmjVqlVKSEhQ586dNWTIEM2YMaNMjn95fdMXX3yhevXquey7vCi9vGsA8PuxZgnATWXLli1XvQ4PD79m/9q1ays+Pl7vv/++Zs2apQULFkiSwsPDtXv3bp0/f97Zd9OmTfLw8FCzZs0UEBCgunXrauvWrc79ly5dUlJSkvN1ixYtZLfbdfToUTVp0sRlCw0NvW4NACoH7iwBcCu5ublKS0tzafPy8nIuil6+fLnat2+vu+++W4sXL9a2bdv0z3/+s8hjTZo0Se3atVPLli2Vm5urlStXOoNVnz59NHnyZMXHx2vKlCn66aefNGzYMPXr10/BwcGSpBEjRuiVV15R06ZN1bx5c73xxhvKzMx0Hr969eoaPXq0nnvuORUWFuruu+9WVlaWNm3aJH9/f8XHxxtrAFA5EJYAuJXVq1erbt26Lm3NmjVTSkqKJOnFF1/U0qVL9eyzz6pu3br64IMP1KJFiyKP5e3trfHjx+vw4cPy9fXVPffco6VLl0qS/Pz8tGbNGo0YMUJ33nmn/Pz81KNHD73xxhvO8aNGjdKpU6cUHx8vDw8P/eUvf1H37t2VlZXl7PPSSy+pdu3amjZtmn788UcFBgbqj3/8o55//vnr1gCgcrBZ1hUfCgIAbspms+mTTz7h60YAlCnWLAEAABgQlgAAAAxYswTgpsGqAgDlgTtLAAAABoQlAAAAA8ISAACAAWEJAADAgLAEAABgQFgCAAAwICwBAAAYEJYAAAAMCEsAAAAG/w9PNex5odi6KAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_train = loss_arr\n",
    "episodes = range(0,len(loss_train))\n",
    "plt.plot(episodes, loss_train, 'g', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MLP' object has no attribute 'w_weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/chrispickett/Desktop/DL/Ass1.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/chrispickett/Desktop/DL/Ass1.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(mlp\u001b[39m.\u001b[39;49mw_weights, mlp\u001b[39m.\u001b[39mv_weights)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'MLP' object has no attribute 'w_weights'"
     ]
    }
   ],
   "source": [
    "print(mlp.w_weights, mlp.v_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]] [[1.0444802524378831, 0.955519747562117], [-0.955519747562117, -1.0444802524378831], [-0.955519747562117, -1.0444802524378831]]\n"
     ]
    }
   ],
   "source": [
    "mlp.set_learning_rate(0.001)\n",
    "mlp.sgd()\n",
    "print(mlp.w_weights, mlp.v_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_synth\n",
    "(xtrain, ytrain), (xval, yval), num_cls = load_synth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_min = xtrain.min()\n",
    "t_max = xtrain.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr, t_min, t_max):\n",
    "    norm_arr = []\n",
    "    diff = t_max - t_min\n",
    "    diff_arr = arr.max() - arr.min()    \n",
    "    for i in arr:\n",
    "        temp = (((i - arr.min())*diff)/diff_arr) + t_min\n",
    "        norm_arr.append(temp)\n",
    "    return norm_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "norm_train_x = normalize(xtrain, 0, 1)\n",
    "norm_val_x = normalize(xval, 0, 1)\n",
    "\n",
    "norm_train_y = normalize(ytrain, 0, 1)\n",
    "norm_val_y = normalize(yval, 0, 1)\n",
    "print(yval[50])\n",
    "print(norm_val_y[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 60000\n"
     ]
    }
   ],
   "source": [
    "print(len(xtrain), len(ytrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_arr(num_cls, t):\n",
    "    arr = [0] * num_cls\n",
    "    arr[t] = 1\n",
    "    return arr\n",
    "# target_arr(2, 0)\n",
    "# 0 if 0 == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a_learning_rate = 1e-4\n",
    "mlp = MLP()\n",
    "mlp.set_learning_rate(a_learning_rate)\n",
    "\n",
    "losses = []\n",
    "epochs = 5\n",
    "\n",
    "dldh = [0.0, 0.0, 0.0]\n",
    "dldk = [0.0, 0.0, 0.0]\n",
    "dldo = [0.0, 0.0]\n",
    "dldy = [0.0, 0.0]\n",
    "\n",
    "dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "dldb = [0.0, 0.0, 0.0]\n",
    "dldc = [0.0, 0.0]\n",
    "     \n",
    "w_weights = [[1.0, 1.0, 1.0], [-1.0, -1.0, -1.0]]\n",
    "b_weights = [0.0, 0.0, 0.0] \n",
    "v_weights = [[1.0, 1.0], [-1.0, -1.0], [-1.0, -1.0]]  # rand_weights(3, 2) # # \n",
    "c_weights = [0.0, 0.0]\n",
    "\n",
    "for j in range(epochs):\n",
    "    loss_avg = []\n",
    "    \n",
    "    dldw = [[0.0, 0.0, 0.0], [0.0, 0.0, 0.0]]\n",
    "    dldb = [0.0, 0.0, 0.0]\n",
    "    dldv = [[0.0, 0.0], [0.0, 0.0], [0.0, 0.0]]\n",
    "    dldc = [0.0, 0.0]\n",
    "    \n",
    "    for i in range(len(norm_train_x)):\n",
    "        x1, x2 = norm_train_x[i]\n",
    "        y = 0 if norm_train_y[i] == 1 else 1 \n",
    "        t_targets = target_arr(num_cls, y)\n",
    "        \n",
    "        x_inputs = [x1, x2]\n",
    "        \n",
    "        y_outputs, h_hidden = mlp.forward(x_inputs, w_weights, b_weights, v_weights, c_weights)\n",
    "        loss = mlp.loss(y_outputs, t_targets)\n",
    "        \n",
    "        w_pri, b_pri, v_pri, c_pri = mlp.backward(y_outputs, t_targets, h_hidden, v_weights, x_inputs, dldw, dldb, dldv, dldc)\n",
    "        \n",
    "        dldw += w_pri\n",
    "        dldb += b_pri\n",
    "        dldv += v_pri\n",
    "        dldc += c_pri\n",
    "        \n",
    "        \n",
    "        if i % 1000 == 0:\n",
    "            losses.append(loss)\n",
    "            \n",
    "    v_weights, w_weights, c_weights, b_weights = mlp.sgd(a_learning_rate, w_weights, b_weights, v_weights, c_weights, dldw, dldb, dldv, dldc)\n",
    "    \n",
    "        \n",
    "\n",
    "       \n",
    "       \n",
    "    # loss_arr.append(loss)\n",
    "        \n",
    "        # mlp.set_inputs([x1, x2])\n",
    "        # mlp.set_targets(t_arr)\n",
    "        \n",
    "        # loss = mlp.forward()\n",
    "        # loss_avg.append(loss)\n",
    "    \n",
    "            # mlp.backward()\n",
    "        # mlp.sgd()\n",
    "    \n",
    "    # score = 0\n",
    "    # tot = len(norm_val_x)\n",
    "    # for i in range(tot):\n",
    "    #     x1, x2 = norm_val_x[i]\n",
    "    #     y = 0 if norm_val_y[i] == 1 else 1 \n",
    "    #     t_arr = target_arr(num_cls, y)\n",
    "        \n",
    "    #     mlp.set_inputs([x1, x2])\n",
    "    #     mlp.set_targets(t_arr)\n",
    "        \n",
    "    #     mlp.forward()\n",
    "    #     if mlp.t_targets[0] == 1 and mlp.y_outputs[0] > 0.5:\n",
    "    #         score += 1\n",
    "    # print(f'accuracy: {score / tot}')\n",
    "        \n",
    "    # losses.append(sum(loss_avg)/len(loss_avg))\n",
    "            \n",
    "\n",
    "loss_train = losses\n",
    "episodes = range(0,len(losses))\n",
    "plt.plot(episodes, loss_train, 'g', label='Training loss')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "score = 0\n",
    "tot = len(norm_val_x)\n",
    "for i in range(tot):\n",
    "    x1, x2 = norm_val_x[i]\n",
    "    y = 0 if norm_val_y[i] == 1 else 1 \n",
    "    t_arr = target_arr(num_cls, y)\n",
    "    \n",
    "    mlp.set_inputs([x1, x2])\n",
    "    mlp.set_targets(t_arr)\n",
    "    \n",
    "    loss = mlp.forward()\n",
    "    losses.append(loss)\n",
    "    # print(mlp.y_outputs, mlp.t_targets, loss)\n",
    "    if mlp.t_targets[0] == 1 and mlp.y_outputs[0] > 0.5:\n",
    "        score += 1\n",
    "        \n",
    "print(f'accuracy: {score / tot}')\n",
    "        \n",
    "# loss_train = losses\n",
    "# episodes = range(0,len(losses))\n",
    "# plt.plot(episodes, loss_train, 'g', label='Validation loss')\n",
    "# plt.title('Validation loss')\n",
    "# plt.xlabel('Epochs')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6652479955699665, 0.33475200443003356]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Continuing the code from where we left off.\n",
    "\n",
    "# We need to import the math module for exp() and uniform from random module for initializing weights and biases.\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Since the neural network in the image has specific weights and biases assigned,\n",
    "# we need to initialize our neurons with those exact values.\n",
    "# For the purpose of this example, I will assume the values are known and manually input them.\n",
    "\n",
    "# Assuming we have 2 inputs, 2 neurons with sigmoid activation in the hidden layer,\n",
    "# and 2 neurons with softmax activation in the output layer as per the image.\n",
    "\n",
    "# Neuron class definition\n",
    "class Neuron:\n",
    "    def __init__(self, weights, bias):\n",
    "        self.weights = weights\n",
    "        self.bias = bias\n",
    "\n",
    "    def activate(self, inputs, activation_function):\n",
    "        # Weighted sum of inputs + bias\n",
    "        z = sum(weight * input for weight, input in zip(self.weights, inputs)) + self.bias\n",
    "        return activation_function(z)\n",
    "\n",
    "# Neural Network class definition\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Manually setting the weights and biases to match the image provided\n",
    "        # Hidden layer with sigmoid activation\n",
    "        self.hidden_neurons = [\n",
    "            Neuron(weights=[1, -1], bias=-1),\n",
    "            Neuron(weights=[1, -1], bias=1),\n",
    "        ]\n",
    "        # Output layer with softmax activation\n",
    "        self.output_neurons = [\n",
    "            Neuron(weights=[1, 1], bias=0),\n",
    "            Neuron(weights=[-1, -1], bias=0),\n",
    "        ]\n",
    "\n",
    "    def feedforward(self, inputs):\n",
    "        # Pass inputs through the hidden layer\n",
    "        hidden_layer_output = [neuron.activate(inputs, sigmoid) for neuron in self.hidden_neurons]\n",
    "\n",
    "        # Pass hidden layer outputs through the output layer\n",
    "        output_layer_output = [neuron.activate(hidden_layer_output, sigmoid) for neuron in self.output_neurons]\n",
    "\n",
    "        # Apply softmax to the output layer's output\n",
    "        return softmax(output_layer_output)\n",
    "\n",
    "def sigmoid(x):\n",
    "    \"\"\"Sigmoid activation function.\"\"\"\n",
    "    return 1 / (1 + math.exp(-x))\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Softmax activation function.\"\"\"\n",
    "    exps = [math.exp(i) for i in x]\n",
    "    sum_exps = sum(exps)\n",
    "    softmax_output = [j/sum_exps for j in exps]\n",
    "    return softmax_output\n",
    "\n",
    "# Let's now re-run the feedforward operation with these functions defined.\n",
    "nn_output = nn.feedforward(input_data)\n",
    "nn_output\n",
    "\n",
    "# Instantiating the neural network\n",
    "nn = NeuralNetwork()\n",
    "\n",
    "# Example input to feedforward through the network\n",
    "# Since the actual input values are not provided, we'll use dummy inputs\n",
    "input_data = [1, -1]\n",
    "\n",
    "# Feedforwarding through the network\n",
    "nn_output = nn.feedforward(input_data)\n",
    "nn_output\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
